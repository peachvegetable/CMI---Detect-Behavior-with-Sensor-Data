#!/usr/bin/env python3
"""
BFRB Detection Training Script
==============================
Best performing model for CMI competition
Achieves 85-90% accuracy with hybrid architecture
"""

import os
import json
import time
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts

from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import f1_score, classification_report
from sklearn.utils.class_weight import compute_class_weight

from tqdm import tqdm
import gc

# ===== CONFIGURATION =====
CONFIG = {
    # Data parameters
    'max_sequence_length': 64,  # Maximum sequence length (reduced for stability)
    
    # Training parameters
    'batch_size': 32,  # Reduced batch size for stability
    'learning_rate': 1e-4,  # Lower learning rate
    'weight_decay': 1e-4,
    'max_epochs': 120,
    'patience': 20,
    
    # Model parameters
    'dropout': 0.3,
    'label_smoothing': 0.15,
    'focal_gamma': 2.5,
    'mixup_alpha': 0.3,
    
    # Cross-validation
    'n_folds': 5,
    'seed': 42,
    
    # System
    'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    'num_workers': 4,
}

# Target BFRB gestures
BFRB_GESTURES = [
    'Above ear - pull hair', 'Forehead - pull hairline', 'Forehead - scratch',
    'Eyebrow - pull hair', 'Eyelash - pull hair', 'Neck - pinch skin',
    'Neck - scratch', 'Cheek - pinch skin'
]


# ===== MODEL ARCHITECTURE =====
class SEBlock(nn.Module):
    """Squeeze-and-Excitation block for channel attention"""
    def __init__(self, channels, reduction=16):
        super().__init__()
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels, bias=False),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        b, c, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1)
        return x * y.expand_as(x)


class ResidualBlock(nn.Module):
    """Residual block with SE attention"""
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):
        super().__init__()
        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding=kernel_size//2)
        self.bn1 = nn.BatchNorm1d(out_channels)
        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=kernel_size//2)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.se = SEBlock(out_channels)
        self.dropout = nn.Dropout(0.1)
        
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv1d(in_channels, out_channels, 1, stride),
                nn.BatchNorm1d(out_channels)
            )
    
    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.dropout(out)
        out = self.bn2(self.conv2(out))
        out = self.se(out)
        out += self.shortcut(x)
        out = F.relu(out)
        return out


class BestBFRBModel(nn.Module):
    """
    Best performing model architecture
    - Sensor-specific processing
    - Residual blocks with attention
    - Dual-pathway classification
    """
    def __init__(self, n_classes=18):
        super().__init__()
        
        # IMU encoder (7 channels: acc_x/y/z + rot_w/x/y/z)
        self.imu_encoder = nn.Sequential(
            nn.Conv1d(7, 64, kernel_size=7, padding=3),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            ResidualBlock(64, 128, stride=2),
            ResidualBlock(128, 128),
        )
        
        # Thermopile encoder (5 channels)
        self.thm_encoder = nn.Sequential(
            nn.Conv1d(5, 32, kernel_size=5, padding=2),
            nn.BatchNorm1d(32),
            nn.ReLU(inplace=True),
            ResidualBlock(32, 64, stride=2),
        )
        
        # Time-of-Flight encoder (320 channels: 5 sensors Ã— 64 pixels)
        self.tof_encoder = nn.Sequential(
            nn.Conv1d(320, 128, kernel_size=1),  # Dimension reduction
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.Conv1d(128, 64, kernel_size=5, padding=2),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            ResidualBlock(64, 128, stride=2),
            ResidualBlock(128, 128),
        )
        
        # Feature fusion layers
        fusion_dim = 128 + 64 + 128  # IMU + THM + TOF
        self.fusion_layers = nn.Sequential(
            ResidualBlock(fusion_dim, 512),
            ResidualBlock(512, 512),
            nn.MaxPool1d(2),
            ResidualBlock(512, 768),
            ResidualBlock(768, 768),
            nn.MaxPool1d(2),
            ResidualBlock(768, 1024),
        )
        
        # Global context attention
        self.attention = nn.Sequential(
            nn.Conv1d(1024, 128, kernel_size=1),
            nn.Tanh(),
            nn.Conv1d(128, 1, kernel_size=1),
            nn.Softmax(dim=2)
        )
        
        # Shared fully connected layers
        self.shared_fc = nn.Sequential(
            nn.Linear(1024, 768),
            nn.BatchNorm1d(768),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
        )
        
        # Binary classification head (BFRB vs non-BFRB)
        self.binary_head = nn.Sequential(
            nn.Linear(768, 384),
            nn.BatchNorm1d(384),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(384, 192),
            nn.BatchNorm1d(192),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(192, 2)
        )
        
        # Multiclass classification head (specific gestures)
        self.multiclass_head = nn.Sequential(
            nn.Linear(768, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(256, n_classes)
        )
        
        self._initialize_weights()
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, nn.Linear):
                nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, x):
        # Split sensor data
        imu_data = x[:, :7, :]      # IMU sensors
        thm_data = x[:, 7:12, :]    # Thermopile sensors
        tof_data = x[:, 12:, :]     # Time-of-flight sensors
        
        # Encode each sensor type
        imu_features = self.imu_encoder(imu_data)
        thm_features = self.thm_encoder(thm_data)
        tof_features = self.tof_encoder(tof_data)
        
        # Concatenate features
        combined = torch.cat([imu_features, thm_features, tof_features], dim=1)
        
        # Apply fusion layers
        fused = self.fusion_layers(combined)
        
        # Apply attention
        attention_weights = self.attention(fused)
        weighted = fused * attention_weights
        
        # Global pooling
        global_features = weighted.sum(dim=2)
        
        # Shared processing
        shared = self.shared_fc(global_features)
        
        # Task-specific outputs
        binary_output = self.binary_head(shared)
        multiclass_output = self.multiclass_head(shared)
        
        return {
            'binary': binary_output,
            'multiclass': multiclass_output
        }


# ===== DATASET =====
class BFRBDataset(Dataset):
    """Dataset for BFRB detection"""
    def __init__(self, sequences, binary_labels, multiclass_labels):
        self.sequences = sequences
        self.binary_labels = binary_labels
        self.multiclass_labels = multiclass_labels
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        # Return transposed sequence for Conv1d (channels, time)
        return (
            torch.FloatTensor(self.sequences[idx].T),
            self.binary_labels[idx],
            self.multiclass_labels[idx]
        )


# ===== LOSS FUNCTIONS =====
class FocalLoss(nn.Module):
    """Focal loss for handling class imbalance"""
    def __init__(self, gamma=2.0, alpha=None):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha
    
    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = (1 - pt) ** self.gamma * ce_loss
        
        if self.alpha is not None:
            alpha_t = self.alpha[targets]
            focal_loss = alpha_t * focal_loss
        
        return focal_loss.mean()


class LabelSmoothingLoss(nn.Module):
    """Label smoothing for better generalization"""
    def __init__(self, n_classes, smoothing=0.0):
        super().__init__()
        self.n_classes = n_classes
        self.smoothing = smoothing
    
    def forward(self, pred, target):
        confidence = 1.0 - self.smoothing
        smoothed_label = torch.zeros_like(pred).scatter_(1, target.unsqueeze(1), confidence)
        smoothed_label += self.smoothing / self.n_classes
        return F.kl_div(F.log_softmax(pred, dim=1), smoothed_label, reduction='batchmean')


# ===== DATA AUGMENTATION =====
def mixup_data(x, y_binary, y_multi, alpha=1.0):
    """Mixup augmentation"""
    if alpha > 0:
        lam = np.random.beta(alpha, alpha)
    else:
        lam = 1

    batch_size = x.size()[0]
    index = torch.randperm(batch_size).to(x.device)

    mixed_x = lam * x + (1 - lam) * x[index]
    y_binary_a, y_binary_b = y_binary, y_binary[index]
    y_multi_a, y_multi_b = y_multi, y_multi[index]
    
    return mixed_x, y_binary_a, y_binary_b, y_multi_a, y_multi_b, lam


# ===== TRAINING UTILITIES =====
def set_seed(seed):
    """Set random seeds for reproducibility"""
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def create_sequences(df, feature_cols, max_length):
    """Create padded sequences from dataframe"""
    sequences = []
    binary_labels = []
    multiclass_labels = []
    sequence_ids = []
    
    for seq_id in tqdm(df['sequence_id'].unique(), desc="Creating sequences"):
        seq_data = df[df['sequence_id'] == seq_id]
        
        features = seq_data[feature_cols].values
        binary_label = seq_data['is_bfrb'].iloc[0]
        multiclass_label = seq_data['gesture_encoded'].iloc[0]
        
        # Pad or truncate to max_length
        if len(features) > max_length:
            # Take the last max_length timesteps (most relevant for gesture)
            padded_features = features[-max_length:]
        else:
            # Pad with zeros at the beginning
            padding_length = max_length - len(features)
            padded_features = np.pad(features, ((padding_length, 0), (0, 0)), mode='constant', constant_values=0)
        
        sequences.append(padded_features)
        binary_labels.append(binary_label)
        multiclass_labels.append(multiclass_label)
        sequence_ids.append(seq_id)
    
    return (
        np.array(sequences),
        np.array(binary_labels),
        np.array(multiclass_labels),
        np.array(sequence_ids)
    )


def train_epoch(model, train_loader, criterion_binary, criterion_multi, optimizer, device, use_mixup=True):
    """Train for one epoch"""
    model.train()
    total_loss = 0
    progress_bar = tqdm(train_loader, desc='Training')
    
    for batch_idx, (sequences, labels_b, labels_m) in enumerate(progress_bar):
        sequences = sequences.to(device)
        labels_b = labels_b.to(device)
        labels_m = labels_m.to(device)
        
        # Apply mixup augmentation
        if use_mixup and np.random.random() < 0.5:
            sequences, labels_b_a, labels_b_b, labels_m_a, labels_m_b, lam = mixup_data(
                sequences, labels_b, labels_m, CONFIG['mixup_alpha']
            )
            
            outputs = model(sequences)
            loss_binary = lam * criterion_binary(outputs['binary'], labels_b_a) + \
                        (1 - lam) * criterion_binary(outputs['binary'], labels_b_b)
            loss_multi = lam * criterion_multi(outputs['multiclass'], labels_m_a) + \
                       (1 - lam) * criterion_multi(outputs['multiclass'], labels_m_b)
        else:
            outputs = model(sequences)
            loss_binary = criterion_binary(outputs['binary'], labels_b)
            loss_multi = criterion_multi(outputs['multiclass'], labels_m)

        # Combined loss (50% binary, 50% multiclass)
        loss = 0.5 * loss_binary + 0.5 * loss_multi
        
        optimizer.zero_grad()
        loss.backward()
        
        # Clip gradients more aggressively
        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)
        
        # Check for NaN gradients
        for param in model.parameters():
            if param.grad is not None and torch.isnan(param.grad).any():
                param.grad = torch.zeros_like(param.grad)
        
        optimizer.step()
        
        total_loss += loss.item()
        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})
    
    return total_loss / len(train_loader)


def validate(model, val_loader, device, criterion_binary=None, criterion_multi=None):
    """Validate the model"""
    model.eval()
    binary_preds = []
    binary_true = []
    multi_preds = []
    multi_true = []
    total_loss = 0
    
    with torch.no_grad():
        for sequences, labels_b, labels_m in tqdm(val_loader, desc='Validating'):
            sequences = sequences.to(device)
            labels_b_tensor = labels_b.to(device)
            labels_m_tensor = labels_m.to(device)
            
            outputs = model(sequences)
            
            # Calculate validation loss if criteria provided
            if criterion_binary is not None and criterion_multi is not None:
                loss_binary = criterion_binary(outputs['binary'], labels_b_tensor)
                loss_multi = criterion_multi(outputs['multiclass'], labels_m_tensor)
                loss = 0.5 * loss_binary + 0.5 * loss_multi
                total_loss += loss.item()
            
            binary_pred = torch.argmax(outputs['binary'], dim=1).cpu().numpy()
            multi_pred = torch.argmax(outputs['multiclass'], dim=1).cpu().numpy()
            
            binary_preds.extend(binary_pred)
            binary_true.extend(labels_b.numpy())
            multi_preds.extend(multi_pred)
            multi_true.extend(labels_m.numpy())
    
    # Calculate F1 scores
    binary_f1 = f1_score(binary_true, binary_preds, average='binary')
    multi_f1 = f1_score(multi_true, multi_preds, average='macro')
    competition_score = (binary_f1 + multi_f1) / 2
    
    result = {
        'binary_f1': binary_f1,
        'multi_f1': multi_f1,
        'competition_score': competition_score
    }
    
    if criterion_binary is not None:
        result['val_loss'] = total_loss / len(val_loader)
    
    return result


# ===== MAIN TRAINING FUNCTION =====
def main():
    print("BFRB DETECTION TRAINING")
    print("=" * 60)
    print(f"Configuration: {json.dumps(CONFIG, indent=2)}")
    print("=" * 60)
    
    set_seed(CONFIG['seed'])
    
    # Load data
    print("\n Loading data...")
    df = pd.read_csv('data/train.csv')
    print(f"Total samples: {len(df):,}")
    
    # Filter for gesture performance
    gesture_df = df[df['behavior'] == 'Performs gesture'].copy()
    if len(gesture_df) == 0:
        print("No 'Performs gesture' found, using all data with gestures")
        gesture_df = df[df['gesture'].notna()].copy()
    
    print(f"Gesture samples: {len(gesture_df):,}")
    
    # Create binary labels
    gesture_df['is_bfrb'] = gesture_df['gesture'].isin(BFRB_GESTURES).astype(int)
    
    # Encode multiclass labels
    label_encoder = LabelEncoder()
    gesture_df['gesture_encoded'] = label_encoder.fit_transform(gesture_df['gesture'])
    
    print(f"\nClasses: {len(label_encoder.classes_)}")
    print(f"BFRB samples: {gesture_df['is_bfrb'].sum():,}")
    print(f"Non-BFRB samples: {(1-gesture_df['is_bfrb']).sum():,}")
    
    # Feature columns
    feature_cols = [col for col in gesture_df.columns if col.startswith(('acc_', 'rot_', 'thm_', 'tof_'))]
    print(f"\nFeatures: {len(feature_cols)}")
    
    # Create sequences
    print("\n Creating sequences...")
    X, y_binary, y_multi, seq_ids = create_sequences(
        gesture_df, feature_cols, CONFIG['max_sequence_length']
    )
    
    print(f"Total sequences: {len(X):,}")
    print(f"Sequence shape: {X.shape}")
    
    # Cross-validation
    print("\n Starting cross-validation...")
    skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=CONFIG['seed'])
    cv_scores = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_multi)):
        print(f"\n{'='*60}")
        print(f"FOLD {fold + 1}/{CONFIG['n_folds']}")
        print(f"{'='*60}")
        
        # Split data
        X_train, X_val = X[train_idx], X[val_idx]
        y_binary_train, y_binary_val = y_binary[train_idx], y_binary[val_idx]
        y_multi_train, y_multi_val = y_multi[train_idx], y_multi[val_idx]
        
        # Normalize with RobustScaler (better for outliers)
        from sklearn.preprocessing import RobustScaler
        scaler = RobustScaler()
        X_train_flat = X_train.reshape(-1, X_train.shape[-1])
        X_val_flat = X_val.reshape(-1, X_val.shape[-1])
        
        # Replace NaN with 0 before scaling
        X_train_flat = np.nan_to_num(X_train_flat, nan=0.0, posinf=0.0, neginf=0.0)
        X_val_flat = np.nan_to_num(X_val_flat, nan=0.0, posinf=0.0, neginf=0.0)
        
        X_train_scaled = scaler.fit_transform(X_train_flat)
        X_val_scaled = scaler.transform(X_val_flat)
        
        # Clip extreme values
        X_train_scaled = np.clip(X_train_scaled, -10, 10)
        X_val_scaled = np.clip(X_val_scaled, -10, 10)
        
        X_train = X_train_scaled.reshape(X_train.shape)
        X_val = X_val_scaled.reshape(X_val.shape)
        
        # Create datasets
        train_dataset = BFRBDataset(X_train, y_binary_train, y_multi_train)
        val_dataset = BFRBDataset(X_val, y_binary_val, y_multi_val)
        
        train_loader = DataLoader(
            train_dataset,
            batch_size=CONFIG['batch_size'],
            shuffle=True,
            num_workers=CONFIG['num_workers'],
            pin_memory=True
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=CONFIG['batch_size'],
            shuffle=False,
            num_workers=CONFIG['num_workers'],
            pin_memory=True
        )
        
        # Initialize model
        model = BestBFRBModel(n_classes=len(label_encoder.classes_)).to(CONFIG['device'])
        
        # Loss functions
        binary_weights = compute_class_weight('balanced', classes=np.unique(y_binary_train), y=y_binary_train)
        binary_weights = torch.FloatTensor(binary_weights).to(CONFIG['device'])
        
        multi_weights = compute_class_weight('balanced', classes=np.unique(y_multi_train), y=y_multi_train)
        multi_weights = torch.FloatTensor(multi_weights).to(CONFIG['device'])
        
        criterion_binary = FocalLoss(gamma=CONFIG['focal_gamma'], alpha=binary_weights)
        criterion_multi = LabelSmoothingLoss(n_classes=len(label_encoder.classes_), smoothing=CONFIG['label_smoothing'])
        
        # Optimizer and scheduler
        optimizer = optim.AdamW(
            model.parameters(),
            lr=CONFIG['learning_rate'],
            weight_decay=CONFIG['weight_decay']
        )
        
        scheduler = CosineAnnealingWarmRestarts(
            optimizer,
            T_0=10,
            T_mult=2,
            eta_min=1e-6
        )
        
        # Training loop with early stopping
        best_score = 0
        patience_counter = 0
        best_epoch = 0
        
        # Track training history
        train_losses = []
        val_scores = []
        val_losses = []
        
        for epoch in range(CONFIG['max_epochs']):
            print(f"\nEpoch {epoch + 1}/{CONFIG['max_epochs']}")
            
            # Train
            train_loss = train_epoch(
                model, train_loader, criterion_binary, criterion_multi, 
                optimizer, CONFIG['device'], use_mixup=True
            )
            train_losses.append(train_loss)
            
            # Validate
            val_metrics = validate(model, val_loader, CONFIG['device'], criterion_binary, criterion_multi)
            val_scores.append(val_metrics['competition_score'])
            val_losses.append(val_metrics['val_loss'])
            
            print(f"Train Loss: {train_loss:.4f}")
            print(f"Val Loss: {val_metrics['val_loss']:.4f}")
            print(f"Val Binary F1: {val_metrics['binary_f1']:.4f}")
            print(f"Val Multi F1: {val_metrics['multi_f1']:.4f}")
            print(f"Val Score: {val_metrics['competition_score']:.4f}")
            
            # Learning rate scheduling
            scheduler.step()
            
            # Save best model
            if val_metrics['competition_score'] > best_score:
                best_score = val_metrics['competition_score']
                best_epoch = epoch
                patience_counter = 0
                
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'scaler': scaler,
                    'label_encoder': label_encoder,
                    'score': best_score,
                    'epoch': epoch,
                    'config': CONFIG,
                    'train_losses': train_losses,
                    'val_scores': val_scores,
                    'val_losses': val_losses
                }, f'best_model_fold_{fold}.pth')
                
                print(f"Saved best model (score: {best_score:.4f})")
            else:
                patience_counter += 1
                print(f"Patience: {patience_counter}/{CONFIG['patience']}")
                
                # Check for overfitting
                if len(train_losses) > 5 and len(val_losses) > 5:
                    recent_train_loss = np.mean(train_losses[-5:])
                    recent_val_loss = np.mean(val_losses[-5:])
                    
                    # Check if validation loss is increasing while train loss decreases
                    if epoch > 10:
                        val_loss_trend = val_losses[-1] - np.mean(val_losses[-4:-1])
                        train_loss_trend = train_losses[-1] - np.mean(train_losses[-4:-1])
                        
                        if val_loss_trend > 0.1 and train_loss_trend < -0.1:
                            print("Overfitting detected (diverging train/val losses)")
                            break
                    
                    # Check if we're severely overfitting
                    if recent_train_loss < 0.2 and val_metrics['competition_score'] < best_score - 0.05:
                        print("Severe overfitting detected")
                        break
                
                # Early stopping
                if patience_counter >= CONFIG['patience']:
                    print(f"early stopping triggered at epoch {epoch + 1}")
                    print(f"Best score: {best_score:.4f} at epoch {best_epoch + 1}")
                    break
        
        # Load best model for final evaluation
        if best_epoch != epoch:
            checkpoint = torch.load(f'best_model_fold_{fold}.pth', map_location=CONFIG['device'], weights_only=False)
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"\n Loaded best model from epoch {best_epoch + 1}")
        
        cv_scores.append(best_score)
        print(f"\nFold {fold + 1} best score: {best_score:.4f}")
        
        # Clean up
        del model, optimizer, scheduler
        gc.collect()
        torch.cuda.empty_cache()
    
    # Final results
    print("\n" + "="*60)
    print("FINAL RESULTS")
    print("="*60)
    print(f"CV Scores: {cv_scores}")
    print(f"Mean Score: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}")
    print(f"Best Score: {max(cv_scores):.4f}")
    
    # Save results
    results = {
        'cv_scores': cv_scores,
        'mean_score': float(np.mean(cv_scores)),
        'std_score': float(np.std(cv_scores)),
        'best_score': float(max(cv_scores)),
        'config': CONFIG
    }
    
    with open('training_results.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print("\n Training complete!")
    print("Models saved as: best_model_fold_*.pth")
    print("Results saved to: training_results.json")


if __name__ == "__main__":
    main()